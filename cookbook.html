<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />
<title>cookbook.rst</title>
<style type="text/css">

* {
    font-family: Muli, Helvetica, sans-serif;
}

body {
    background-color: #ECEFF1;
    margin-left: 20rem;
}
body > * {
    background-color: white;
    line-height: 1.6;
    padding: 2rem;
    max-width: 80%;
}

.sidebar,
.marginal,
.admonition.marginal {
  max-width: 18rem;
  border: none;
  background-color: #ECEFF1;
  margin: 0.5rem;
  margin-left: -22rem;
  padding: 0.5rem;
  position:fixed;
  clear: left;
  float: left;
}
.sidebar {
  width: -20%;
}

div.topic.contents ul {
    list-style-type: none;
}
div.topic.contents a {
    text-decoration: none;
    color: inherit;
}

a.toc-backref {
    text-decoration: none;
    color: inherit;
}

p.subtitle a {
    text-decoration: none;
    color: inherit;
}

table {
    border-collapse: collapse;
}

.header {
    background-color: #5C6BC0;
    color: white;
    margin:0;

}

.header strong {
    font-size: 3em;
}
</style>
</head>
<body>
<div class="header">
TechNES AI Best Practices Group:
<hr class="header"/>
</div>
<div class="document">


<div class="contents sidebar topic" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#summary" id="id2">Summary</a></li>
<li><a class="reference internal" href="#introduction" id="id3">Introduction</a></li>
<li><a class="reference internal" href="#overview-key-concepts-and-terminology" id="id4">Overview: Key Concepts and Terminology</a></li>
<li><a class="reference internal" href="#ai-ml-overview-and-trade-offs" id="id5">AI/ML Overview and Trade-offs</a><ul>
<li><a class="reference internal" href="#aims-of-this-document" id="id6">Aims of this document:</a></li>
</ul>
</li>
<li><a class="reference internal" href="#candidate-documentation-technologies" id="id7">Candidate “Documentation” Technologies</a><ul>
<li><a class="reference internal" href="#requirements" id="id8">Requirements</a></li>
<li><a class="reference internal" href="#candidates" id="id9">Candidates</a></li>
<li><a class="reference internal" href="#non-candidates" id="id10">Non-candidates</a></li>
</ul>
</li>
<li><a class="reference internal" href="#top-level-decision-steps" id="id11">Top Level Decision steps</a></li>
<li><a class="reference internal" href="#overview-how-algorithms-learn" id="id12">Overview: How Algorithms Learn</a></li>
<li><a class="reference internal" href="#neural-network-algorithm-families" id="id13">Neural Network Algorithm Families</a></li>
<li><a class="reference internal" href="#non-neural-network-algorithm-families" id="id14">Non-Neural Network Algorithm Families</a></li>
<li><a class="reference internal" href="#mathematical-models" id="id15">Mathematical Models</a></li>
<li><a class="reference internal" href="#feed-forward-neural-networks" id="id16">Feed Forward Neural Networks</a></li>
<li><a class="reference internal" href="#recurrent-neural-networks" id="id17">Recurrent Neural Networks</a></li>
<li><a class="reference internal" href="#id1" id="id18">Recurrent Neural Networks</a></li>
</ul>
</div>
<div class="section" id="summary">
<h1><a class="toc-backref" href="#id2">Summary</a></h1>
<p>What is Machine Learning, exactly? Is it the same as Artificial Intelligence?
These terms have exploded in common and industrial usage in the past decade, and
it is increasingly important to be able to understand and talk precisely about
these topics. ML promises to offer firms a new paradigm of automation, yet is
often less transparent than other methods. This means that significant care
must be taken to avoid undetected mistakes leading to misplaced trust in
automated systems that are not performing as expected. Similar problems can
arise from data alone if existing human biases are captured by these
algorithms. For these reasons, this document will guide engineers to:</p>
<ul class="simple">
<li>Demystify the jargon surrounding AI and Machine Learning</li>
<li>Navigate the vast amount of ML theory, techniques and resources available</li>
<li>Solve problems, avoiding common mistakes and wasted efforts</li>
</ul>
<p>It can be used as a reference before, during and after a machine learning
project is developed.</p>
</div>
<div class="section" id="introduction">
<h1><a class="toc-backref" href="#id3">Introduction</a></h1>
<p>“Can machines think?” Was the question posed by Alan Turing in 1950 to open the
field of Artificial Intelligence. He challenged the world, and himself, to
replicate natural (human, animal) intelligence artificially, creating systems
that can think and act rationally. Creating a system that could achieve this to
the level of a human would be an Artificial General Intelligence (AGI), or a
“strong” AI by some definitions. The answer to his question remains unknown to
this day, however it is certainly possible for machines to learn. In the sense
hat algorithms can adjust themselves to improve performance, “Machine Learning”
(a.k.a “weak AI”) is not only possible, but in widespread usage today.</p>
<p>This forms the core distinction between strong AI and ML. Machine learning
algorithms cannot “think” like humans can, but they can use data to “learn” to
improve themselves. In this document we will use “ML” to refer to the class of
algorithm described by weak AI and Machine Learning, and “AI” to refer to
Strong AI and AGI.</p>
<p>Where AGI refers in some way to an artificial equivalent to the human brain, it
is perhaps less intimidating to think of ML as any computer program which learns
through self-adjustment. The gist of ML is that we write a generic algorithm
with a list of settings that determine what the algorithm does. Initially, the
settings are decided randomly, so the algorithm won’t do anything useful. But
then, we can use data to optimise (tweak) those settings to make the algorithm
do what we actually want it to do. Simple!</p>
<p>A great number of techniques come under the umbrella of ML.  These will be
broken down in detail later in this document, however an important category to
consider is called “deep learning” (DL). Yet another term often (mistakenly)
used interchangeably with AI and ML, this refers to a specific subset of ML
algorithm, called deep neural networks. Whereas non-DL methods usually expect
their input to be made of individually useful elements (think eye colour, jaw
length, glasses(Y/N) etc) called “features”, deep neural networks are used to
learn to extract useful features from high dimensional data (think the
individual pixel values from a photo of a face).</p>
<p>Language frames the way we think, thus it is critical to have a strong
understanding of these concepts and associated terminology. Having established
here what we mean when we talk about AI, ML and DL, the first aim of this
document is to clarify all the remaining technical jargon an engineer might
encounter when considering using a machine learning approach to a problem.</p>
<p>Then, armed with this terminology, we can dive deeper into the details of how to
approach building a robust and trustworthy machine learning system.</p>
</div>
<div class="section" id="overview-key-concepts-and-terminology">
<h1><a class="toc-backref" href="#id4">Overview: Key Concepts and Terminology</a></h1>
<p>In this section, we introduce and overview some of the key concepts and
terminology that are important in understanding and discussing AI and machine
learning technology. This section is not intended to serve as an exhaustive
discussion of the topics in question, but as an introduction to the key points
and vocabulary that will frame the rest of the discussion on this topic. Key
terms and concepts will be highlighted for the reader, with links to a more
detailed description of the term in the appendix.</p>
<p>To briefly review what we discussed in the introduction: the type of
intelligence and learning in algorithms that we are interested in in this
manual are algorithms that learn mathematical models of the world from some
data, in order to make predictions about other unseen or future data. One
important idea and terminology that we need to consider first is structured
data and unstructured data.</p>
<p>Structured vs Unstructured Data
AI and Machine Learning models are no different from any other piece of code in
requiring their input data to follow a consistent format. Unfortunately, data
collected in the real world rarely follows the type of structure and
organization that is needed for ingestion by an AI or Machine learning
algorithm, and in many cases the work done to transform data into an
appropriate structured format is some of the most important work done in any AI
and Machine Learning pipeline. We make this distinction between data that has
been put into a useful structured format as structured data, and data that
exists in a raw, unprocessed format as unstructured data.</p>
<p>When dealing with data in the real world, we will often split it up into
categories or types. One such distinction often made that is especially
important in the context of AI and Machine Learning is the split of data into
continuous data and discrete data. Continuous data is data that can take on
any number of infinite values across a given range, for example, a measure of
millimeters of rainfall per hour. Discrete data on the other hand is any type
of data that falls into a fixed number of categories. These categories can be
both ordinal data in which there is a natural ordering between the categories
(shoe size, for example), and nominal data, where the categories are distinct
(eye color, for example). While this distinction is important for many parts of
AI and Machine Learning, the distinction between whether an AI and Machine
Learning algorithm is trying to predict continuous and discrete data is so
important that it has its own nomenclature of regression and classification
algorithms respectively.</p>
<p>While these distinctions are important, we suggest that readers focus on the
practical and functional aspects of this distinction rather than its
definitional aspects unless they are doing hard math. Consider, for example,
the case of the price paid at a market for an apple. While it may be
definitionally appropriate to consider the price as a discrete number (unless
our merchant is willing to accept fractional coins), it may be practically
more suitable to consider it as continuous. Avoiding such problems is why
statisticians use measure theory, which we caution the reader is even less
fun than it sounds.</p>
<p>Regression vs Classification Algorithms
The distinction between regression (continuous output data) and classification
(discrete output data) is particularly important in AI and Machine Learning
algorithms, because the type of data that the algorithm outputs has a
significant effect on how it must function. Notably, some algorithms (e.g.
Support Vector Machines) are really only designed to function in one of these
modalities, and require significant adaptations to perform (likely very poorly)
in the other.</p>
<p>While we have been discussing some of the concepts and terminology around data
to this point, we have used the terms “learn”, “learning” and “learning from
data” to describe what our algorithms do without really making it explicit what
we actually mean by this. One of the reasons that we’ve avoided doing this is
that “learning” in the context we’re discussing it is conveniently, without
further qualifiers, a term that covers several different ideas. These
differences stem from the way that we use data in order to “learn”. The
most prominent of two of these ideas are supervised learning and unsupervised
learning, which are concerned whether we learn from data that list the correct
output the algorithms should produce for some given input data (labeled data),
or simply the input data themselves (unlabeled data).</p>
<p>Supervised vs Unsupervised vs Reinforcement vs Other Learning
We use the nomenclature of Supervised vs Unsupervised (vs others) to describe
the way in which our algorithms are learning. In Supervised learning, we learn
from matched input data/output data pairs, data for which we already have the
correct output the algorithms should predict for a set of given inputs
(“learning by example”). We call this data labeled data, because our set of
input data is labeled with the corresponding correct solutions.For example,
we might be interested in predicting the future prices of the stock market from
economic indications, by looking at how these economic indicators have predicted
its historical past prices. In Unsupervised learning, we only have access to the
input data without any corresponding output solution attached. We call this data
unlabeled data, and our unsupervised learning algorithms and are generally
interested in predicting some quality of this data (“pattern learning”). For
example, we might be detecting unusual anomalies of electrical usage in the
grid.</p>
<p>While it is generally preferable to use supervised learning when we can
because learning by example is easier, there are many situations in which
unsupervised approaches are more appropriate. Even putting aside the fact
that unlabeled data is easier to collect (since we don’t need to label it),
for many problems supervised approaches are simply not practical. In our
electrical grid example above, it would be infeasible to train a supervised
model to do similar anomaly detection.  By definition, anomalies are rare and
unusual data points that fall outside of the usual observations in the data.
Creating a labeled dataset of them would be both impractical, and any
supervised algorithm that used it would be prescriptive - it would only catch
anomalies similar to anomalies we’ve trained on, where an unsupervised approach
instead catches ones that are dissimilar to everything we’ve seen so far.</p>
<p>There are also several other learning approaches that fit within the
supervised/unsupervised dichotomy discussed so far. A common one is
Reinforcement Learning. In Reinforcement Learning, the algorithm is not fed a
set of data, but selects which piece of data it wants to learn from in future
from the pieces of data it has had up until now. Another common paradigm is
semi-supervised learning, in which an algorithm learns from some set data that
is labeled, and some (usually larger) set of data that is unlabelled.</p>
</div>
<div class="section" id="ai-ml-overview-and-trade-offs">
<h1><a class="toc-backref" href="#id5">AI/ML Overview and Trade-offs</a></h1>
<div class="section" id="aims-of-this-document">
<h2><a class="toc-backref" href="#id6">Aims of this document:</a></h2>
<ul class="simple">
<li>Key considerations to be aware of in employing AI/ML in an embedded system</li>
<li>Guidance towards application appropriate solutions given relevant trade-offs and system-level requirements</li>
<li>Doesn’t appear to be anything like this online</li>
<li>Who are the end users and how will they use it?</li>
<li>Tim likes “cheat sheets”</li>
<li>How affected by the type of users (Verification engineer, designer, …)</li>
<li>Only industry or also academic (note specific to TechNeS, and aimed a professional engineers)</li>
<li>Can we reuse academic courses</li>
<li>How much more detail needed</li>
<li>What prior experience assumed (general and AI specific)?</li>
<li>Make it narrower, focus on applications, examples specific users</li>
<li>Should I even use AI?</li>
<li>Need decision steps, choice of algorithm is towards the end, may need to try several</li>
<li>different collateral for stages as user gains expertise</li>
<li>Start with good and bad examples of AI in use</li>
<li>how to balance information overload: break into steps, separate guides for different problems</li>
</ul>
</div>
</div>
<div class="section" id="candidate-documentation-technologies">
<h1><a class="toc-backref" href="#id7">Candidate “Documentation” Technologies</a></h1>
<div class="section" id="requirements">
<h2><a class="toc-backref" href="#id8">Requirements</a></h2>
<ul class="simple">
<li>Must be good for collaborative work</li>
<li>Must generate at least PDF, HTML, ideally help files</li>
<li>Must be able to add mixed media (images/video)</li>
<li>Needs version control</li>
<li>Must be freely available to the group</li>
</ul>
</div>
<div class="section" id="candidates">
<h2><a class="toc-backref" href="#id9">Candidates</a></h2>
<ul class="simple">
<li>Restructured Text</li>
<li>DocBook/DITA</li>
</ul>
</div>
<div class="section" id="non-candidates">
<h2><a class="toc-backref" href="#id10">Non-candidates</a></h2>
<ul class="simple">
<li>Overleaf/LaTex - can’t generate structured HTML</li>
<li>MS Word/OpenOffice/LibreOffice - can’t generate structured HTML</li>
<li>Canva - proprietary</li>
</ul>
</div>
</div>
<div class="section" id="top-level-decision-steps">
<h1><a class="toc-backref" href="#id11">Top Level Decision steps</a></h1>
<dl class="docutils">
<dt>Step 1:</dt>
<dd>Train user in vocabulary to be able to address the problem accurately.  Enable conversation between engineering and marketing to refine product (may be highly disruptively).</dd>
<dt>Step 2:</dt>
<dd>Can you relate your problem to an existing problem AI has already solved (data architecture and algorithm). Or do you need a new AI approach. Is it possible with AI? Or do you even need AI? We need to create the inverse table: what AI can do. Allow user to refine from general to specific AI choice</dd>
<dt>Step 3:</dt>
<dd>Identify candidate solutions (data architecture and algorithm), cross-check features against table in this document. Do this hierarchically.  Identify any wider impact on the system by choice of AI.</dd>
<dt>Step 4:</dt>
<dd>Identify AI engineering skills needed (training/buy-in)</dd>
<dt>End step:</dt>
<dd>Engineer can implement their project</dd>
</dl>
</div>
<div class="section" id="overview-how-algorithms-learn">
<h1><a class="toc-backref" href="#id12">Overview: How Algorithms Learn</a></h1>
<table border="1" class="docutils">
<colgroup>
<col width="12%" />
<col width="7%" />
<col width="81%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">How AI Algorithms learn</th>
<th class="head" colspan="2">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>Supervised</td>
<td colspan="2"><dl class="first last docutils">
<dt>The model is trained on ‘labelled’ data, where known correct outputs are labelled alongside the input data to enable future classification or predictions, sepcialized variants</dt>
<dd><ul class="first last simple">
<li>Semi-supervised: Not all the data is labelled or reliable, so need to mix with unsupervised techniques to pre-process the data</li>
<li>Self-Supervised: Applying a pre-trained (pretext) supervised learning model to an unsupervised learning problem to address a specific problem</li>
</ul>
</dd>
</dl>
</td>
</tr>
<tr><td>Unsupervised</td>
<td colspan="2">The model is presented with unlabeled data and so has to exploit inherent qualities in the input data, such as clustering or density / distribution to ‘learn’ how to process it.</td>
</tr>
<tr><td>Reinforcement</td>
<td colspan="2">Technically a class of supervised learning, but usually categorized separately. The model operates without training but in an environment where it’s decision outputs (based on
given input data) will elicit reward signals (positive and negative feedback). It must thereby optimise it’s internal model of likely success from a given current state.</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="neural-network-algorithm-families">
<h1><a class="toc-backref" href="#id13">Neural Network Algorithm Families</a></h1>
<table border="1" class="docutils">
<colgroup>
<col width="12%" />
<col width="7%" />
<col width="81%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">AI Algorithm Families</th>
<th class="head" colspan="2">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>Feed Forward Neural
Networks</td>
<td colspan="2">A collection of layered, interconnected nodes which sum weighted inputs and applies an activation (mathematical) function to derive output. Input data travels in one direction
only and exits through output nodes. Before use FFN’s are trained using a training dataset and thus use a supervised learning approach.</td>
</tr>
<tr><td>Recurrent Neural
Networks</td>
<td colspan="2">By feeding intermediate layer outputs back to the inputs, better prediction of outcomes is achieved. In this way, some information the network possessed in the previous time-
step is remembered by a memory function.</td>
</tr>
<tr><td>Unsupervised Neural
Networks</td>
<td colspan="2">The network does not receive a prior training dataset and, instead, is presented with unlabeled data. The network therefore has to exploit inherent qualities in the input data
to ‘learn’ how to process it. Typically ‘training’ occurs ‘on the job’ e.g. using competitive rather than error-correction learning.</td>
</tr>
<tr><td>Graph Neural
Networks</td>
<td colspan="2">&nbsp;</td>
</tr>
<tr><td>Spiking Neural
Networks</td>
<td colspan="2">&nbsp;</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="non-neural-network-algorithm-families">
<h1><a class="toc-backref" href="#id14">Non-Neural Network Algorithm Families</a></h1>
<table border="1" class="docutils">
<colgroup>
<col width="12%" />
<col width="7%" />
<col width="81%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">AI Algorithm Families</th>
<th class="head" colspan="2">Description</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>Linear and related</td>
<td colspan="2"><ul class="first last simple">
<li>Linear Regression</li>
<li>Spline Interpolation</li>
<li>Support Vector Machine (SVM)</li>
</ul>
</td>
</tr>
<tr><td>Tree Based Methods</td>
<td colspan="2"><ul class="first last simple">
<li>Decision trees</li>
<li>Random Forests</li>
<li>Boosted/Bagged trees</li>
<li>Gradient Boosted trees</li>
</ul>
</td>
</tr>
<tr><td>Nearest Neighbor</td>
<td colspan="2"><ul class="first last simple">
<li>K-nearest neighbor</li>
<li>k-means</li>
</ul>
</td>
</tr>
<tr><td>Statistical</td>
<td colspan="2"><ul class="first last simple">
<li>Naieve Bayes</li>
<li>T-test/F-test</li>
<li><dl class="first docutils">
<dt>Markov Chain Monte Carlo</dt>
<dd><ul class="first last">
<li>Simulated Annealing</li>
<li>Dynamic Causal Modelling</li>
</ul>
</dd>
</dl>
</li>
<li>Full Bayesian Methods</li>
</ul>
</td>
</tr>
<tr><td>Symbolic</td>
<td colspan="2"><ul class="first last simple">
<li>Inductive Logic Programming</li>
</ul>
</td>
</tr>
<tr><td>Bio-Inspired</td>
<td colspan="2"><ul class="first last simple">
<li>Genetic Algorithms/Genetic Programming</li>
<li>Any Colony Optimization</li>
<li>Particle Swarm Optimization</li>
</ul>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="mathematical-models">
<h1><a class="toc-backref" href="#id15">Mathematical Models</a></h1>
<table border="1" class="docutils">
<colgroup>
<col width="12%" />
<col width="24%" />
<col width="8%" />
<col width="7%" />
<col width="24%" />
<col width="24%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Algorithm</th>
<th class="head">Description</th>
<th class="head">Type</th>
<th class="head">Learning</th>
<th class="head">Benefits</th>
<th class="head">Application</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>Linear Regression</td>
<td>Line-fit algorithm, according to: y=ax+b.</td>
<td>Regression</td>
<td>Supervised</td>
<td>Efficient for linear relationships e.g. trends
or forecasts</td>
<td>Drug-dosage relationships</td>
</tr>
<tr><td>Logistic Regression</td>
<td>Discrete outcomes from linear data.</td>
<td>Classification</td>
<td>Supervised</td>
<td>Efficient for linear relationships when the data
set is linearly separable</td>
<td>Medical data, Credit scoring,
Language processing</td>
</tr>
<tr><td>Decision Tree</td>
<td><p class="first">Data set is split recursively into a tree</p>
<p class="last">comprising decision nodes and outcome leaves.</p>
</td>
<td><p class="first">Classification</p>
<p class="last">(or Regression)</p>
</td>
<td>Supervised</td>
<td>Fast and efficient to run. Easy to understand
and interpret. Can handle any type of data</td>
<td>Data mining, Planning, Fault diagnosis</td>
</tr>
<tr><td>Support Vector Machine</td>
<td>SVM algorithms classify data in n
(no of features)-dimensional space.</td>
<td>Classification
(or Regression)</td>
<td>Supervised</td>
<td>Handles high dimensional data, separating things
into (typically two) groups with more separation
than other algorithms by projecting the data
into a more easily separable space.</td>
<td>Face detection, Handwriting recognition,
Image classification</td>
</tr>
<tr><td>Naieve Bayes</td>
<td>Simple classification algorithm using
conditional probability of an event based on
prior events.</td>
<td>Classification</td>
<td>Supervised</td>
<td>Requires less training data than other
algorithms and handles both continuous and
discrete data. Highly scalable with the number
of predictors and data points. Fast runtime
enables real-time predictions.</td>
<td>Face recognition, Weather prediction,
Medical diagnosis, News classification, Spam
email detection based on word frequency vs real
email.</td>
</tr>
<tr><td>K-nearest Neighbor</td>
<td>Classification based on prior classification of
the majority of (K) nearest neighbors with a
distance function. (Becomes computationally
expensive as dataset and dimensionality scale).</td>
<td><p class="first">Classification</p>
<p class="last">(or Regression)</p>
</td>
<td>Supervised</td>
<td>Simple to implement and effective for data with
low dimensionality. There is no training period
(data is stored only for use later) which makes
KNN faster than other (trained) algorithms.
Furthermore, new training data can be added
seamlessly.</td>
<td>Text mining, Finance, Medical, Facial
recognition, Recommendation systems (e.g. music
based on age, genre, country)</td>
</tr>
<tr><td>K-Means</td>
<td>Classifies data into K clusters through
recursive clustering of data with similar
features.</td>
<td><p class="first">Classification</p>
<p class="last">(or Regression)</p>
</td>
<td>Unsupervised</td>
<td>Simple to implement and results are easy to
interpret. Handles large datasets well and
guarantees convergence. Easily adapts to changes
in data.</td>
<td>Image segmentation, Image compression, Biological
data, Fraud detection, Transport data analysis</td>
</tr>
<tr><td>Random Forest</td>
<td>Average across multiple decision trees
trained on various subsets of the data.</td>
<td><p class="first">Classification</p>
<p class="last">(or Regression)</p>
</td>
<td>Supervised</td>
<td>Reliable predictions that can be understood
easily. Handles large datasets efficiently.
More accurate than a single decision tree.</td>
<td>Finance risk, Medical trends, Stock trading,
E-commerce</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="feed-forward-neural-networks">
<h1><a class="toc-backref" href="#id16">Feed Forward Neural Networks</a></h1>
<table border="1" class="docutils">
<colgroup>
<col width="13%" />
<col width="63%" />
<col width="24%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">ANN</th>
<th class="head">Description</th>
<th class="head">Application</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>Feed Forward Neural
Network</td>
<td>Collection of interconnected nodes, arranged in layers. The basic unit is the Perceptron (or Threshold Logic Unit) - a
single node which sums weighted inputs and applies an activation function to derive the output. In larger networks with
multiple nodes, input data travels in one direction, passing through a number of input nodes and exiting through output
nodes. In a multilayer network (three or more successive layers), each node is connected to all nodes in the next layer.
The output is a function (activation function) of the sum of all inputs multiplied by their respective weights. During
training (Supervised Learning), the weights are calculated through backpropagation.</td>
<td>Data Compression, Pattern Recognition, Machine
diagnostics, Image / Speech / Handwriting
Recognition</td>
</tr>
<tr><td>Convolutional Neural
Network</td>
<td>A form of FFN Inspired by the animal visual cortex. The CNN is a 3D arrangement of neurons, employing convolutional
processing rather than multiplication in its hidden layers. Each neuron in the first (convolutional) layer only
processes information from a small part of the input field. The network understands images in parts and computes these
operations multiple times to process the full image. Nodes are connected only locally to nearby neighbors unlike an FFN.</td>
<td>Video recognition, semantic parsing and
paraphrase detection.</td>
</tr>
<tr><td>Radial Basis Function
Neural Network</td>
<td>A three-layer FFN where the hidden layer uses a non-linear RBF activation function. Classification is performed by
measuring the input’s similarity to previously trained data points.</td>
<td>System modelling &amp; control, time series
prediction, image classification</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="recurrent-neural-networks">
<h1><a class="toc-backref" href="#id17">Recurrent Neural Networks</a></h1>
<table border="1" class="docutils">
<colgroup>
<col width="13%" />
<col width="63%" />
<col width="24%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">ANN</th>
<th class="head">Description</th>
<th class="head">Application</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>Recurrent Neural
Network</td>
<td>Layer outputs fed back to the inputs help in predicting outcomes. The first layer is typically a feed forward neural
network followed by a recurrent layer where some information it had in the previous time-step is remembered by a memory
function.</td>
<td>Handwriting / Speech recognition, Language
modelling &amp; translation, Text summarization,
Image tagging</td>
</tr>
<tr><td>Long short-term memory
(LSTM)</td>
<td>A more sophisticated RNN which uses memory gates to regulate information flow through the network so as to improve
training by avoiding loss of small gradient data during backpropagation.</td>
<td>Unsegmented connected handwriting recognition,
speech recognition, robot control, video games</td>
</tr>
<tr><td>Sequence to Sequence
(Seq2Seq)</td>
<td>Two Recurrent Neural Networks working simultaneously. One RNN is configured as an encoder, processing the input data and
the second as a decoder which derives the output based on the encoder’s final internal state.</td>
<td>Machine translation, Speech recognition, Text
summarization, Conversational models /
Chat-bots, Video captioning</td>
</tr>
<tr><td>Attention network</td>
<td>Attention networks mimic cognitive attention by enhancing some parts of the input data while diminishing other parts;
i.e. to focus attention on a small but important part of the data. Learning which part of the data is more important
than others depends on the context and is trained by the gradient descent algorithm.</td>
<td>Reasoning, Complex language processing.
Multi-sensory data processing
(sound, images, video, and text)</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="id1">
<h1><a class="toc-backref" href="#id18">Recurrent Neural Networks</a></h1>
<table border="1" class="docutils">
<colgroup>
<col width="13%" />
<col width="63%" />
<col width="24%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">ANN</th>
<th class="head">Description</th>
<th class="head">Application</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>Self-Organizing Map /
Kohonen Net</td>
<td>Unsupervised technique producing a 1 or 2-D representation of a higher dimensional dataset such that similar observations
are clustered to aid onward analysis. The network is trained using competitive rather than error-correction learning so
that nodes ‘move’ within the dataspace to generate a map of the reference data. During iterative training, node weights
change in order to ‘cluster’ the neurons together to reduce the distance between neuron and input. The map can then
classify observations for the input space by finding the node with the closest weight vector to the input space vector.</td>
<td>Visualizing data in large datasets, Project
prioritization, Seismic or Failure mode
analysis, Artwork creation</td>
</tr>
<tr><td>Generative adversarial
network (GAN)</td>
<td>Two neural networks compete in a zero-sum game. The generator network learns to generate new data with the same
statistics as the training set in an unsupervised way, as it is indirectly trained by the discriminator (the second
neural network) which can tell how realistic a given input is while it is itself being updated dynamically. GANs are
also useful for semi-supervised, fully supervised and reinforcement learning.</td>
<td>Image-to-Image / Text-to-Image Translation,
Semantic image manipulation and creation,
Photo editing / blending, Face aging, Video
prediction, Super-resolution</td>
</tr>
<tr><td>Autoencoder</td>
<td>An autoencoder is a Feed Forward Neural Network which learns an efficient representation (encoding) for a set of
unlabeled data , through unsupervised learning. The autoencoder consists of two main parts: an encoder that maps the
input into the code, and a decoder that maps the code to a reconstruction of the input. The encoding is refined by
attempting to regenerate the input from the encoding whilst minimizing the difference between input and output. The
network therefore generates new data rather than predicting target values and is thus unsupervised.</td>
<td>Dimensionality reduction, Information
retrieval, Anomaly detection Feature
extraction, Image denoising and compression,
Image search, Image generation</td>
</tr>
</tbody>
</table>
</div>
</div>
</body>
</html>
