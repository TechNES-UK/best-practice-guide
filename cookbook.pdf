<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />
<title>cookbook.rst</title>
<style type="text/css">

* {
    font-family: Muli, Helvetica, sans-serif;
}

body {
    background-color: #ECEFF1;
    margin-left: 20rem;
}
body > * {
    background-color: white;
    line-height: 1.6;
    padding: 2rem;
    max-width: 80%;
}

.sidebar,
.marginal,
.admonition.marginal {
  max-width: 18rem;
  border: none;
  background-color: #ECEFF1;
  margin: 0.5rem;
  margin-left: -22rem;
  padding: 0.5rem;
  position:fixed;
  clear: left;
  float: left;
}
.sidebar {
  width: -20%;
}

div.topic.contents ul {
    list-style-type: none;
}
div.topic.contents a {
    text-decoration: none;
    color: inherit;
}

a.toc-backref {
    text-decoration: none;
    color: inherit;
}

p.subtitle a {
    text-decoration: none;
    color: inherit;
}

table {
    border-collapse: collapse;
}

.header {
    background-color: #5C6BC0;
    color: white;
    margin:0;

}

.header strong {
    font-size: 3em;
}
</style>
</head>
<body>
<div class="header">
TechNES AI Best Practices Group:
<hr class="header"/>
</div>
<div class="document">


<div class="contents sidebar topic" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><a class="reference internal" href="#summary" id="id1">Summary</a></li>
<li><a class="reference internal" href="#target-audience" id="id2">Target Audience</a></li>
<li><a class="reference internal" href="#introduction" id="id3">Introduction</a></li>
<li><a class="reference internal" href="#overview-key-concepts-and-terminology" id="id4">Overview: Key Concepts and Terminology</a><ul>
<li><a class="reference internal" href="#putting-it-together-creating-modern-ai-and-machine-learning" id="id5">Putting it Together: Creating Modern AI and Machine Learning</a></li>
</ul>
</li>
<li><a class="reference internal" href="#running-ai-projects" id="id6">Running AI Projects</a><ul>
<li><a class="reference internal" href="#should-i-ai" id="id7">Should I AI?</a></li>
<li><a class="reference internal" href="#ai-project-decisions" id="id8">AI Project Decisions</a></li>
<li><a class="reference internal" href="#ai-project-workflow" id="id9">AI Project Workflow</a></li>
</ul>
</li>
<li><a class="reference internal" href="#data" id="id10">Data</a><ul>
<li><a class="reference internal" href="#the-importance-of-data" id="id11">The Importance of Data</a></li>
<li><a class="reference internal" href="#collecting-data" id="id12">Collecting Data</a></li>
<li><a class="reference internal" href="#managing-data" id="id13">Managing Data</a></li>
</ul>
</li>
<li><a class="reference internal" href="#building-ai-and-machine-learning-models" id="id14">Building AI and Machine Learning Models</a><ul>
<li><a class="reference internal" href="#decisions" id="id15">Decisions</a></li>
<li><a class="reference internal" href="#decision-making-flowchart" id="id16">Decision Making Flowchart</a></li>
<li><a class="reference internal" href="#neural-networks" id="id17">Neural Networks</a></li>
<li><a class="reference internal" href="#worked-examples" id="id18">Worked Examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#pitfalls-and-common-problems" id="id19">Pitfalls and Common Problems</a></li>
<li><a class="reference internal" href="#resources" id="id20">Resources</a></li>
<li><a class="reference internal" href="#appendix" id="id21">Appendix</a></li>
</ul>
</div>
<div class="section" id="summary">
<h1><a class="toc-backref" href="#id1">Summary</a></h1>
<p>Artificial Intelligence (AI) and Machine Learning (ML) technologies are key to
many modern engineering projects due to their ability to solve many problems
that are difficult or impossible with other methods. While most engineers will
find themselves enjoying a significant overlap between these techniques and
their existing skill set, they are also liable to find that AI and Machine
Learning is its own field with its own unique demands and (often hidden)
pitfalls. While there are many resources available for self teaching, it is
generally assumed the practitioner is either an absolute beginner to
engineering, or already a seasoned expert in AI and ML. In this document, we
provide a practical guide to AI and Machine learning for  electronic systems
engineers who already have a strong base of knowledge in electronic systems but
no specialised expertise. This guide will be practice focused, with the goal of
helping engineers to make good decisions and avoid problems. The guide will
cover, among many others areas:</p>
<ul class="simple">
<li>Technical Language and Core Concepts</li>
<li>Data, Collection and Common Problems</li>
<li>Deploying AI and Machine Learning, with Worked Examples</li>
<li>Existing resources, where to find them and how best to use them</li>
<li>Common Pitfalls, how to avoid and how to solve</li>
</ul>
</div>
<div class="section" id="target-audience">
<h1><a class="toc-backref" href="#id2">Target Audience</a></h1>
<p>The target audience for this guide is electronic systems engineers with little
to no specific expertise in AI and Machine Learning techniques. It will be
assumed, because of this background, that readers will have a base level of
competence in programming and mathematics, though the guide will err on the
side of caution in respect of assumed knowledge. We may, for example, assume
our reader has knowledge of concepts in basic calculus, but are unlikely to
assume that they are able to remember any specific formula. We are also assuming
that the primary interest in practically deploying these techniques rather than
understanding the theory and context of their development. For readers
interested in a more theoretical treatment, we list several texts in the
resources section appropriate to a range of different levels of background
knowledge.</p>
</div>
<div class="section" id="introduction">
<h1><a class="toc-backref" href="#id3">Introduction</a></h1>
<p>The terms Artificial Intelligence and Machine Learning both lend themselves to
the idea that we are creating a program that can, in some respect, think and
learn in the same way a person can. While it may be possible to create systems
that are capable of this, the current technologies that are deployed in practice
are much more restricted in scope. Current, practical Artificial Intelligence
and Machine Learning technology generally refers to programs that are of a
statistical, or statistically adjacent nature, and that use data to fit some
specified mathematical model. While these techniques are proving extremely
valuable in solving otherwise difficult or intractable problems, the
fundamentals of the techniques are neither exceptionally novel nor complicated.
In this guide, we aim to show just how simple it can be to deploy these
techniques in practice, especially for an audience that already has knowledge
of electronic systems engineering.</p>
<p>It is important to acknowledge that, despite the above, no specific definition
of Artificial Intelligence and Machine Learning that is universally agreed on
exists. Furthermore, lacking any significant advancement in our understanding
of what cognition, intelligence, and learning actually mean, this state of
affairs is likely to continue. Given the practical focus of this guide, it would
not be profitable for us to enter into this debate at any length. We will
therefore, universally use the term “AI and Machine Learning” to refer to
algorithms that are the subject of this guide, and that learn to
<strong>parameterize</strong> a mathematical model from data.</p>
<p>This guide is structured into 5 sections. In the first section, we discuss the
key concepts and terminology that are used in AI and Machine Learning and
briefly discuss how they come together to motivate us to create the field in its
current form. With this important background covered, we then move on to
discussing the practicalities of AI and Machine Learning projects at a high
level. We discuss where it’s appropriate to deploy these technologies, a high
level workflow and decision making process, and what management of these
projects looks like. Having covered this, we then begin to drill down into
the details of these projects. We open this discussion with a review of the
key role data, and how it can be managed. This is followed with an extensive
discussion on the implementation and decision making process of deployment of
these algorithms with worked examples. We close with a list of pitfalls, common
problems and solutions, and a link to useful further resources.</p>
</div>
<div class="section" id="overview-key-concepts-and-terminology">
<h1><a class="toc-backref" href="#id4">Overview: Key Concepts and Terminology</a></h1>
<p>In this section, we introduce and overview some of the key concepts and
terminology that are important in understanding and discussing AI and machine
learning technology. This section is not intended to serve as an exhaustive
discussion of the topics in question, but as an introduction to the key points
and vocabulary that will frame the rest of the discussion on this topic. Key
terms and concepts will be <strong>highlighted</strong> for the reader, with links to a more
detailed description of the term in the appendix.</p>
<p>To briefly review what we discussed in the introduction: the type of
intelligence and learning in algorithms that we are interested in in this
manual are algorithms that learn mathematical models of the world from some
data, in order to make predictions about other unseen or future data. One
important idea that we need to consider first is <strong>structured
data</strong> and <strong>unstructured data</strong>.</p>
<p>Breakaway: Structured vs Unstructured Data
AI and Machine Learning models are no different from any other computer program
in that they require their input data to follow a consistent format.
Unfortunately, data collected in the real world rarely follows the type of
structure and organization that is needed for ingestion by an AI or Machine
learning algorithm, and in many cases the work done to transform data into an
appropriate structured format is some of the most important work done in any AI
and Machine Learning pipeline. We make this distinction between data that has
been put into a useful structured format as <strong>structured data</strong>, and data that
exists in a raw, unprocessed format as <strong>unstructured data</strong>.</p>
<p>When dealing with data in the real world, we will often split it up into
categories or types. One such distinction often made that is especially
important in the context of AI and Machine Learning is the split of data into
<strong>continuous</strong> data and <strong>discrete</strong> data. Continuous data can take on any
number of infinite values across a given range, for example, a measure of
rainfall per hour. Discrete data on the other hand is any type of data that falls into a
fixed number of categories. These categories can be both <strong>ordinal</strong> data in which
there is a natural ordering between the categories (shoe size, for example), and
<strong>nominal</strong> data, where the categories are distinct (eye color, for example). While
this distinction is important for many parts of AI and Machine Learning, the
distinction between whether an AI and Machine Learning algorithm is trying to
predict continuous and discrete data is so important that it has its own
nomenclature of <strong>regression</strong> and <strong>classification</strong> algorithms respectively.</p>
<p>Breakaway: Regression vs Classification Algorithms
The distinction between <strong>regression</strong> (continuous output data) and <strong>classification</strong>
(discrete output data) is particularly important in AI and Machine Learning
algorithms, because the type of data that the algorithm outputs has a
significant effect on how it must function. Notably, some algorithms (e.g.
Support Vector Machines) are only designed to function in one of these
modalities, and require significant adaptations to perform (likely very poorly)
in the other.</p>
<p>While we have been discussing some of the concepts and terminology around data
to this point, we have used the terms “learn”, “learning” and “learning from
data” to describe what our algorithms do without really making it explicit what
we actually mean by this. One of the reasons that we’ve avoided doing this is
that “learning” in the context we’re discussing it is conveniently, without
further qualifiers, a term that covers several different ideas. These
differences stem from the way that we use data in order to “learn”. The
most prominent of two of these ideas are <strong>supervised learning</strong> and <strong>unsupervised
learning</strong>, which are concerned whether we learn from data that list the correct
output the algorithms should produce for some given input data (<strong>labeled data</strong>),
or simply the input data themselves (<strong>unlabeled data</strong>).</p>
<p>Breakaway: Supervised vs Unsupervised vs Reinforcement vs Other Learning
We use the nomenclature of <strong>Supervised</strong> vs <strong>Unsupervised</strong> (vs others) to describe
the way in which our algorithms are learning. In Supervised learning, we learn
from matched input data/output data pairs, data for which we already have the
correct output the algorithms should predict for a set of given inputs
(“learning by example”). We call this data <strong>labeled data</strong>, because our set of
input data is labeled with the corresponding correct solutions.For example,
we might be interested in predicting the future prices of the stock market from
economic indications, by looking at how these economic indicators have predicted
its historical past prices. In Unsupervised learning, we only have access to the
input data without any corresponding output solution attached. We call this data
<strong>unlabeled data</strong>, and our unsupervised learning algorithms and are generally
interested in predicting some quality of this data (“pattern learning”). For
example, we might be detecting unusual anomalies of electrical usage in the
grid.</p>
<p>While it is generally preferable to use supervised learning when we can
because learning by example is easier, there are many situations in which
unsupervised approaches are more appropriate. Even putting aside the fact
that unlabeled data is easier to collect (since we don’t need to label it),
for many problems supervised approaches are simply not practical. In our
electrical grid example above, it would be infeasible to train a supervised
model to do similar anomaly detection.  By definition, anomalies are rare and
unusual data points that fall outside of the usual observations in the data.
Creating a labeled dataset of them would be both impractical, and any
supervised algorithm that used it would be prescriptive - it would only catch
anomalies similar to anomalies we’ve trained on, where an unsupervised approach
instead catches ones that are dissimilar to everything we’ve seen so far.</p>
<p>There are also several other learning approaches that fit within the
supervised/unsupervised dichotomy discussed so far. A common one is
<strong>Reinforcement Learning</strong>. In Reinforcement Learning, the algorithm is not fed a
set of data, but selects which piece of data it wants to learn from in future
from the pieces of data it has had up until now. Another common paradigm is
<strong>semi-supervised learning</strong>, in which an algorithm learns from some set data that
is labeled, and some (usually larger) set of data that is unlabelled.</p>
<div class="section" id="putting-it-together-creating-modern-ai-and-machine-learning">
<h2><a class="toc-backref" href="#id5">Putting it Together: Creating Modern AI and Machine Learning</a></h2>
<p>WIP</p>
</div>
</div>
<div class="section" id="running-ai-projects">
<h1><a class="toc-backref" href="#id6">Running AI Projects</a></h1>
<div class="section" id="should-i-ai">
<h2><a class="toc-backref" href="#id7">Should I AI?</a></h2>
</div>
<div class="section" id="ai-project-decisions">
<h2><a class="toc-backref" href="#id8">AI Project Decisions</a></h2>
</div>
<div class="section" id="ai-project-workflow">
<h2><a class="toc-backref" href="#id9">AI Project Workflow</a></h2>
</div>
</div>
<div class="section" id="data">
<h1><a class="toc-backref" href="#id10">Data</a></h1>
<div class="section" id="the-importance-of-data">
<h2><a class="toc-backref" href="#id11">The Importance of Data</a></h2>
</div>
<div class="section" id="collecting-data">
<h2><a class="toc-backref" href="#id12">Collecting Data</a></h2>
</div>
<div class="section" id="managing-data">
<h2><a class="toc-backref" href="#id13">Managing Data</a></h2>
</div>
</div>
<div class="section" id="building-ai-and-machine-learning-models">
<h1><a class="toc-backref" href="#id14">Building AI and Machine Learning Models</a></h1>
<div class="section" id="decisions">
<h2><a class="toc-backref" href="#id15">Decisions</a></h2>
</div>
<div class="section" id="decision-making-flowchart">
<h2><a class="toc-backref" href="#id16">Decision Making Flowchart</a></h2>
</div>
<div class="section" id="neural-networks">
<h2><a class="toc-backref" href="#id17">Neural Networks</a></h2>
<div class="section" id="architectural-principles-of-neural-networks">
<h3>Architectural Principles of Neural Networks</h3>
<p>Here we break down some of the key ideas that go into building a more
sophisticated neural network than the basic MLP we used in our first example.
Understanding these will allow you to see how even the world’s most complex and
capable neural networks are put together.</p>
<ul>
<li><dl class="first docutils">
<dt>Convolution</dt>
<dd><ul class="first simple">
<li><strong>What:</strong></li>
</ul>
<div class="system-message">
<p class="system-message-title">System Message: WARNING/2 (<tt class="docutils">cookbook.rst</tt>, line 246)</p>
<p>Bullet list ends without a blank line; unexpected unindent.</p>
</div>
<p class="last">A filter with learnable parameters.
* <strong>Why:</strong>
Computer vision has used filters for many decades, designing filters which slide along (convolve with) an image to pick out features such as sharpness, contrast, vertical/horizontal lines etc. The key insight is that if we instead make the parameters in the filter learnable, the algorithm can itself determine what the optimal filters should look like, from the data alone.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Pooling</dt>
<dd><ul class="first simple">
<li><strong>What:</strong></li>
</ul>
<div class="system-message">
<p class="system-message-title">System Message: WARNING/2 (<tt class="docutils">cookbook.rst</tt>, line 251)</p>
<p>Bullet list ends without a blank line; unexpected unindent.</p>
</div>
<p class="last">A dimensionality reduction technique. Similarly to a convolution, a window is selected on the input, and the corresponding output from this window is the largest activation value found in that window. Then the window is shifted, and the process repeats
* <strong>Why:</strong>
Dimensionality reduction can be desirable for many reasons, but pooling has a number of specific advantages. Firstly, it has no parameters to learn, meaning it adds negligible computational requirements during training. Secondly it has been found to be complementary to convolutions. This is likely because convolutions can be thought of as filters searching for specific features, and the pooling then essentially tells the network if those features are present in the given window.</p>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Convolutional Blocks</dt>
<dd><ul class="first last simple">
<li><strong>What:</strong> An architectural design shortcut - a combination of
convolutional layers, pooling layers and regularisers packaged into a block
which is repeated throughout the network.</li>
<li><strong>Why:</strong> Convolutional layers are used to extract local patterns in the
input data. By stacking many convolutional layers on top of each other,
higher level relationships are able to be recognised. In practice, this
means the network is able to perform better (more complex) pattern
recognition, which is what machine learning is all about. Using a repeating
block structure like the one pictured below has been found to be very
effective. Each block contains multiple convolutions and a pooling layer to
reduce dimensionality. Each element of the block is optional and
customisable, but the principle of repeating blocks remains the same.</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Skip Connections</dt>
<dd><ul class="first last simple">
<li><strong>What:</strong> Passing the output of one layer in the network directly to later
layers in the network, ‘skipping’ over the intermediate layers. This can
be done through addition, which requires the dimensions of the layers to
be equal, or through appending, which increases the dimension size.
Appending is the safer choice, though comes at greater computational cost.</li>
<li><strong>Why:</strong> As we make our networks deeper, we are able to extract higher
level features. This is extremely powerful, but some new issues begin to
emerge. Firstly, the low level information can get lost on the way.
Secondly, we can run into the vanishing gradient problem. A neat solution
to diminish both of these issues is to use skip connections.</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Bottlenecks</dt>
<dd><ul class="first last simple">
<li><strong>What:</strong> A bottleneck refers to the shape of the network (big to small).
Often followed by more layers to build the network size back up (small to
big). The bottleneck itself is the smallest layer, which can also be
called the encoding layer.</li>
<li><strong>Why:</strong> Many networks utilise the idea of a bottleneck, even beyond
simple autoencoders (which are nothing more than a bottleneck in
structure). Compressing data through a small encoding layer encourages
the network to extract the most distinguishing features from the data.
This is used in a number of different ways. The encoding itself can be
used to represent the data in a unique and low dimensional form. Or the
second half of the network can use the information from skip connections
and the encoding to infer high level information about the data to solve
problems.</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Recurrence</dt>
<dd><ul class="first last simple">
<li><strong>What:</strong> A network layer which takes as input some data and a ‘state’
vector, and produces a new state vector alongside its other output.</li>
<li><strong>Why:</strong> The state vector represents some understanding about the state at
a given time. The idea then is for the layer to take in some data and
update this understanding, so that the state is different for the next
time step. Without recurrence, networks have no notion of time or way
to relate the data coming in now with what came before. This is necessary
for sequential tasks like video or text recognition, and not necessary for
static tasks such as image recognition, hence the discrepancy.</li>
</ul>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Attention</dt>
<dd><ul class="first last simple">
<li><strong>What:</strong> Weighting each element of a sequence of data, according to how
important (how much attention should be paid to) it, to solve a given
task. Typically, the model will be outputting another sequence, and as
such each element of the output with will require a different set of
attention weights. The full theory behind attention is beyond the scope of
this guide. It is listed here to give a brief intuition behind transformer
models, which are growing in popularity and based on the principle of
attention.</li>
<li><strong>Why:</strong> Attention provides a way for a network to take in sequential data
all at once, learning which input elements each output should pay
attention to. This offers numerous benefits over recurrence, such as the
ability to be processed in parallel (recurrent networks are inherently
sequential so cannot be parallelised), and removing recency bias. Recency
bias being the tendency of RNNs to pay more attention to the most recent
sequence elements, rather than the most relevant.</li>
</ul>
</dd>
</dl>
</li>
</ul>
</div>
<div class="section" id="neural-network-design-and-experimentation-process">
<h3>Neural Network Design and Experimentation Process</h3>
<ol class="arabic">
<li><p class="first">Establish a strong baseline. The first thing to do once your data pipeline
and evaluation metrics are set up, is to try out the simplest neural network
design relevant to your problem. Usually this will be an MLP. The data will
determine the input and output size, so for this make a simple MLP with one
hidden layer. There is no magic formula to tell you how large to make this
hidden layer, the key is to experiment. Start with (input size + output
size)/2 if you are unsure. Train and evaluate. This gives you a benchmark
and some idea of how complex the task will be. If the MLP performs very well,
you may wish to stop there. If not, move on to step 2.</p>
</li>
<li><p class="first">Design a neural network specifically for your problem. How? Google it! More
specifically, scour the internet for a research paper, article or competition
submission that publishes a machine learning model for a problem similar to
yours. All kinds of similarity are useful, working on the same data type (eg
time series, video etc), or the same problem (eg anomaly detection, object
recognition), but ideally both. For this to be successful, it is likely that
the authors have already done a great deal of the work for us in choosing
approximately the right kind of network architecture. Take this as a starting
point.</p>
<blockquote>
<ol class="loweralpha simple">
<li>The closer their problem is to yours, the less we need to experiment with
other architectures</li>
<li>For research papers in particular, models may be more complicated than
necessary as authors are usually proposing a novel method. We can
experiment with removing the more complicated features, if they don’t
affect performance.</li>
<li>If nothing relevant arises, use the baseline model we established earlier
as the starting point.</li>
</ol>
</blockquote>
</li>
<li><p class="first">Iteration and experimentation. Given a baseline (either from step 1 or 2) and
working data pipeline, it may be surprisingly straightforward to test
different ideas, so long as enough computational resources are available.
Bear your initial goals in mind, don’t be afraid to stop iterating when these
are met even if it may be possible to squeeze slightly more performance out
with further experimentation. Very small improvements to measured performance
on test data may not actually translate to a significantly better model in
the real world. APIs such as TensorFlow and PyTorch make adjusting model
architectures as simple as stacking preset functions on top of one and other.
These all come in built with these APIs, and are listed below:</p>
<blockquote>
<ol class="loweralpha">
<li><p class="first">Regularisers: These may improve generalisation performance without
changing the overall architecture.</p>
<blockquote>
<ol class="lowerroman simple">
<li>Dropout</li>
<li>Batch normalisation.</li>
</ol>
</blockquote>
</li>
<li><p class="first">Dimensionality Manipulations: Scale up or down dimensionality. Often
comes at a cost of information loss in favour of computational efficiency.</p>
<blockquote>
<ol class="lowerroman simple">
<li>Max Pooling</li>
</ol>
</blockquote>
</li>
<li><dl class="first docutils">
<dt>Recurrent modules: for sequential data only.</dt>
<dd><ol class="first last lowerroman simple">
<li>LSTM</li>
<li>GRU</li>
</ol>
</dd>
</dl>
</li>
<li><dl class="first docutils">
<dt>Other</dt>
<dd><ol class="first last lowerroman simple">
<li>Convolutions</li>
<li>Skip Connections</li>
</ol>
</dd>
</dl>
</li>
</ol>
</blockquote>
</li>
</ol>
<p>Taking the ideas of others as inspiration, try out some of these ideas and
observe their effects, both individually and in combination. See the
architectural principles section for a breakdown of what each of these do.
Remember, simplicity is key. A useful method to avoid wasted time is to train
and test the model after a given small change, one change at a time.  If
performance doesn’t improve, don’t waste any more time on changes of that kind.
Whereas if you make many changes and then evaluate, you can’t be sure which
changes are having a positive effect.</p>
</div>
</div>
<div class="section" id="worked-examples">
<h2><a class="toc-backref" href="#id18">Worked Examples</a></h2>
</div>
</div>
<div class="section" id="pitfalls-and-common-problems">
<h1><a class="toc-backref" href="#id19">Pitfalls and Common Problems</a></h1>
</div>
<div class="section" id="resources">
<h1><a class="toc-backref" href="#id20">Resources</a></h1>
</div>
<div class="section" id="appendix">
<h1><a class="toc-backref" href="#id21">Appendix</a></h1>
</div>
</div>
</body>
</html>
